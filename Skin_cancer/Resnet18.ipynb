{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\User/.cache\\torch\\hub\\pytorch_vision_v0.5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.5.0', 'resnet18', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "def load_train_data(train_path, train_batch_size, size, shuffle = True):\n",
    "    transformers = transforms.Compose([\n",
    "                    transforms.Resize(size),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    set_data = datasets.ImageFolder(root = train_path, transform = transformers)\n",
    "    return DataLoader(set_data, batch_size = train_batch_size, shuffle = shuffle, num_workers = 1)\n",
    "\n",
    "def load_test_data(test_path, test_batch_size, size, shuffle = True):\n",
    "    transformers = transforms.Compose([transforms.Resize((size, size)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    set_data = datasets.ImageFolder(root = test_path, transform = transformers)\n",
    "    return DataLoader(set_data, batch_size = test_batch_size, shuffle = shuffle, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from Models import ConvNet\n",
    "# from Load import load_data\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "Learning_rate = 0.001\n",
    "Batch_size = 64\n",
    "L2_rate = 0\n",
    "image_size = 256\n",
    "\n",
    "data_size = 9017\n",
    "num_batches = data_size//Batch_size\n",
    "num_classes = 7\n",
    "\n",
    "Train_path = \"C:/Users/User/Desktop/Astghik/Skin_cancer/data/train/\"\n",
    "\n",
    "\n",
    "data_loader = load_train_data(Train_path, Batch_size, image_size)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    crossentropy = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=Learning_rate)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X, y in tqdm(data_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(X) \n",
    "\n",
    "            \n",
    "            loss = crossentropy(out, y)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() \n",
    "\n",
    "            predictions = torch.argmax(out, 1)\n",
    "            epoch_acc += torch.sum(predictions==y).item()\n",
    "\n",
    "        epoch_loss = epoch_loss/num_batches\n",
    "        epoch_acc = epoch_acc/data_size\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(\"ACC:\", epoch_acc, \"LOSS:\", epoch_loss)\n",
    "\n",
    "        torch.save(model.state_dict(),\n",
    "                   f\"C:/Users/User/Desktop/Astghik/Skin_cancer/saved_models/resnet18/ResNet_{epoch}.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:14<00:00, 12.02s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "ACC: 0.7109903515581679 LOSS: 1.0173933938145638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:06<00:00, 11.96s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "ACC: 0.7685482976599756 LOSS: 0.631894037766116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:04<00:00, 11.95s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "ACC: 0.7935011644671177 LOSS: 0.5590380970920835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:08<00:00, 11.97s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "ACC: 0.8132416546523233 LOSS: 0.5052641713193484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:24<00:00, 12.09s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "ACC: 0.8315404236442275 LOSS: 0.4639593618256705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:04<00:00, 11.95s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "ACC: 0.8411888654763225 LOSS: 0.4239538672779288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:09<00:00, 11.98s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "ACC: 0.8528335366529888 LOSS: 0.39949553247009006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:09<00:00, 11.98s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "ACC: 0.8717977154264168 LOSS: 0.34673515994633947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:11<00:00, 12.00s/it]\n",
      "  0%|                                                                                          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "ACC: 0.8846623045358767 LOSS: 0.3135347042764936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 141/141 [28:14<00:00, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "ACC: 0.899412221359654 LOSS: 0.2820188319044454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "#model = ConvNet(7)\n",
    "\n",
    "state_dict = torch.load(\"C:/Users/User/Desktop/Astghik/Skin_cancer/saved_models/resnet18/ResNet_6.model\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "data_size = 998\n",
    "test_batch_size = 64\n",
    "size = 256\n",
    "\n",
    "test_path = \"C:/Users/User/Desktop/Astghik/Skin_cancer/data/test/\"\n",
    "\n",
    "data_loader = load_test_data(test_path, test_batch_size, size, shuffle=False)\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    y_hat = []\n",
    "    y_true = []\n",
    "    for X, y in tqdm(data_loader):\n",
    "        \n",
    "        out = model(X)\n",
    "        \n",
    "        predictions = torch.argmax(out, 1)\n",
    "        acc += torch.sum(predictions == y).item()\n",
    "        y_hat.append(predictions)\n",
    "        y_true.append(y)\n",
    "        \n",
    "    y_hat = torch.cat(y_hat)\n",
    "    y_true = torch.cat(y_true)\n",
    "    acc = acc/data_size\n",
    "    print(acc)\n",
    "    print(classification_report(y_hat, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:10<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8106212424849699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.67      0.43        15\n",
      "           1       0.80      0.62      0.70        66\n",
      "           2       0.72      0.54      0.62       144\n",
      "           3       0.36      0.50      0.42         8\n",
      "           4       0.43      0.69      0.53        70\n",
      "           5       0.92      0.90      0.91       684\n",
      "           6       0.71      0.91      0.80        11\n",
      "\n",
      "    accuracy                           0.81       998\n",
      "   macro avg       0.61      0.69      0.63       998\n",
      "weighted avg       0.83      0.81      0.82       998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test() #6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
