{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hmnist_28_28_RGB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...    pixel2343  pixel2344  \\\n",
       "0        197        154        185        202  ...          173        124   \n",
       "1        123         93        126        158  ...           60         39   \n",
       "2        201        142        160        206  ...          167        129   \n",
       "3        143        103        119        171  ...           44         26   \n",
       "4        215        162        191        225  ...          209        166   \n",
       "\n",
       "   pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "0        138        183        147        166        185        154   \n",
       "1         55         25         14         28         25         14   \n",
       "2        143        159        124        142        136        104   \n",
       "3         36         25         12         17         25         12   \n",
       "4        185        172        135        149        109         78   \n",
       "\n",
       "   pixel2351  label  \n",
       "0        177      2  \n",
       "1         27      2  \n",
       "2        117      2  \n",
       "3         15      2  \n",
       "4         92      2  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    6705\n",
       "6    1113\n",
       "2    1099\n",
       "1     514\n",
       "0     327\n",
       "5     142\n",
       "3     115\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 2352)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.drop(['label'],axis=1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array(df.drop(['label'],axis=1)).reshape(10015,28,28,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b5592b7978>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['label'],axis=1)).reshape(10015,28,28,3)\n",
    "y = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8012, 28, 28, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2003, 28, 28, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32).view(-1, 28*28*3)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).view(-1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).view(-1, 28*28*3)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8012, 2352]), torch.Size([8012]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2352"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28*3, 256)\n",
    "        #self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 7)\n",
    "        #self.fc4 = nn.Linear(64, 7)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "#         x = self.dropout(x)\n",
    "        #x = self.relu(self.fc3(x))\n",
    "#         x = self.dropout(x)\n",
    "       # x = self.relu(self.fc4(x))\n",
    "        x = self.fc3(x)        \n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=2352, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=7, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_index(m, b): \n",
    "    indexes = np.random.permutation(torch.arange(m))    \n",
    "    for i in range(0, m, b):\n",
    "        yield indexes[i:i+b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Train Loss: 2.2309031448364256 Train Acc: 0.5961058412381428\n",
      "Test Loss: 1.3617174173555067 Test Acc: 0.5776335496754867\n",
      "====================\n",
      "Epoch 1:\n",
      "Train Loss: 1.507511253595352 Train Acc: 0.6157014478282576\n",
      "Test Loss: 1.2987829408337992 Test Acc: 0.562656015976036\n",
      "====================\n",
      "Epoch 2:\n",
      "Train Loss: 1.31603686773777 Train Acc: 0.6342985521717424\n",
      "Test Loss: 1.58823827966567 Test Acc: 0.6699950074887668\n",
      "====================\n",
      "Epoch 3:\n",
      "Train Loss: 1.215627347111702 Train Acc: 0.6451572641038442\n",
      "Test Loss: 1.2083804991937452 Test Acc: 0.63554667998003\n",
      "====================\n",
      "Epoch 4:\n",
      "Train Loss: 1.1239262949228286 Train Acc: 0.6440339490763854\n",
      "Test Loss: 1.0528424103413858 Test Acc: 0.6704942586120819\n",
      "====================\n",
      "Epoch 5:\n",
      "Train Loss: 1.0450872381925582 Train Acc: 0.6553919121318023\n",
      "Test Loss: 1.4195650258371908 Test Acc: 0.6684972541188218\n",
      "====================\n",
      "Epoch 6:\n",
      "Train Loss: 1.0325249955654143 Train Acc: 0.6565152271592611\n",
      "Test Loss: 0.9947532819163415 Test Acc: 0.6824762855716425\n",
      "====================\n",
      "Epoch 7:\n",
      "Train Loss: 0.9835953495502472 Train Acc: 0.6677483774338492\n",
      "Test Loss: 0.9247660531151679 Test Acc: 0.691462805791313\n",
      "====================\n",
      "Epoch 8:\n",
      "Train Loss: 0.9882348538637161 Train Acc: 0.6625062406390414\n",
      "Test Loss: 0.9694194351473162 Test Acc: 0.6610084872690963\n",
      "====================\n",
      "Epoch 9:\n",
      "Train Loss: 0.9649211419820786 Train Acc: 0.6723664503245133\n",
      "Test Loss: 1.165816605091095 Test Acc: 0.671992011982027\n",
      "====================\n",
      "Epoch 10:\n",
      "Train Loss: 0.9427626447677613 Train Acc: 0.6721168247628557\n",
      "Test Loss: 0.8918764927694874 Test Acc: 0.6854717923115327\n",
      "====================\n",
      "Epoch 11:\n",
      "Train Loss: 0.9248843880891799 Train Acc: 0.6799800299550673\n",
      "Test Loss: 0.9355678231485428 Test Acc: 0.6879680479281078\n",
      "====================\n",
      "Epoch 12:\n",
      "Train Loss: 0.9193184530735016 Train Acc: 0.677608587119321\n",
      "Test Loss: 0.9678943724401535 Test Acc: 0.672491263105342\n",
      "====================\n",
      "Epoch 13:\n",
      "Train Loss: 0.9057264589071273 Train Acc: 0.6796055916125812\n",
      "Test Loss: 0.9331320043533079 Test Acc: 0.6490264603095357\n",
      "====================\n",
      "Epoch 14:\n",
      "Train Loss: 0.9052029983997345 Train Acc: 0.687343984023964\n",
      "Test Loss: 0.8712631694732174 Test Acc: 0.6949575636545182\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "m = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "crossentropy = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                            weight_decay=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for batch_i in get_batch_index(m, batch_size):\n",
    "        X_batch = X_train[batch_i] \n",
    "        y_batch = y_train[batch_i] \n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(X_batch)\n",
    "        \n",
    "        loss = crossentropy(out, y_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        predictions = torch.argmax(out, 1) \n",
    "        epoch_acc += torch.sum(predictions == y_batch).item()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    for batch_i in range(0, test_size, batch_size):\n",
    "        X_batch = X_test[batch_i:batch_i+batch_size]\n",
    "        y_batch = y_test[batch_i:batch_i+batch_size]\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        out = model(X_batch)\n",
    "\n",
    "        loss = crossentropy(out, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        predictions = torch.argmax(out, 1)\n",
    "        test_acc += torch.sum(predictions == y_batch).item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(\"Train Loss:\", epoch_loss/(m//batch_size), \"Train Acc:\", epoch_acc/m)\n",
    "    print(\"Test Loss:\", test_loss/(test_size//batch_size), \"Test Acc:\", test_acc/test_size)   \n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
